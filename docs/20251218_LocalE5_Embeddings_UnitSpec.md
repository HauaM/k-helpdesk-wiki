# Unit Spec: ë¡œì»¬ E5 ëª¨ë¸ ê¸°ë°˜ ì˜ë¯¸ë¡ ì  ì„ë² ë”© ë„ì…

**ì‘ì„±ì¼**: 2025-12-18
**ë²„ì „**: 1.0 (ì´ˆì•ˆ)
**ìƒíƒœ**: êµ¬í˜„ ì¤€ë¹„ ì™„ë£Œ
**ìš°ì„ ìˆœìœ„**: ğŸ”´ ë†’ìŒ (ì˜ë¯¸ ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ)

---

## 1. ìš”êµ¬ì‚¬í•­ ìš”ì•½

### 1.1 í•µì‹¬ ëª©í‘œ

í˜„ì¬ bag-of-words ê¸°ë°˜ ì„ë² ë”©ì„ **ë¡œì»¬ E5 ëª¨ë¸**ë¡œ êµì²´í•˜ì—¬:
- âœ… **í•œêµ­ì–´ ì™„ë²½ ì§€ì›**: `multilingual-e5-small-ko-v2` ëª¨ë¸ (ê³µì‹ í•œêµ­ì–´ ìµœì í™”)
- âœ… **ì˜ë¯¸ë¡ ì  ê²€ìƒ‰**: ë™ì˜ì–´/ìœ ì‚¬ ê°œë… ì¸ì‹ (ì˜ˆ: "ê²°ì œ ì˜¤ë¥˜" â‰ˆ "ì¹´ë“œ ê²°ì œ ì‹¤íŒ¨")
- âœ… **ë¹„ìš© 0**: ë¡œì»¬ ì‹¤í–‰ (ì™¸ë¶€ API í˜¸ì¶œ ì—†ìŒ)
- âœ… **ë¹ ë¥¸ ì‘ë‹µ**: ìºì‹± + ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ ìµœì í™”
- âœ… **í”„ë¼ì´ë²„ì‹œ**: ë°ì´í„° ì™¸ë¶€ ì „ì†¡ ì—†ìŒ

### 1.2 ë¬¸ì œì  ë¶„ì„

#### í˜„ì¬ ë¬¸ì œ (Bag-of-Words)
```python
# app/vectorstore/pgvector.py:302-319
def _embed_text(self, text: str) -> list[float]:
    tokens = re.findall(r"[\w']+", text.lower())
    vector = [0.0] * 1536  # í† í° ë¹ˆë„ë§Œ ê³„ì‚°
    for token in tokens:
        digest = hashlib.sha256(token.encode("utf-8")).digest()
        bucket = int.from_bytes(digest[:4], "big") % self.dimension
        vector[bucket] += 1.0
```

**ì œì•½ì‚¬í•­:**
| ì œì•½ | í˜„í™© | ì˜í–¥ |
|------|------|------|
| **í•œêµ­ì–´ ì§€ì›** | âŒ (ì •ê·œì‹ ê¸°ë°˜) | "ì‹ ìš©ì¹´ë“œ ê²°ì œ" â†’ ì–´íœ˜ ë¶„ë¦¬ ì‹¤íŒ¨ |
| **ì˜ë¯¸ ì¸ì‹** | âŒ (ë¹ˆë„ë§Œ ê³„ì‚°) | "ê²°ì œ ì˜¤ë¥˜" vs "ì¹´ë“œ ê²°ì œ ì‹¤íŒ¨" â†’ ìœ ì‚¬ë„ ë‚®ìŒ |
| **ë™ì˜ì–´ ì²˜ë¦¬** | âŒ | "ì—ëŸ¬" â‰  "ì˜¤ë¥˜" (ê²€ìƒ‰ ë¶ˆê°€) |
| **ë„ë©”ì¸ ìµœì í™”** | âŒ | ì¼ë°˜ í…ìŠ¤íŠ¸ìš© (ê¸ˆìœµìš© ì•„ë‹˜) |
| **ì„ë² ë”© ì°¨ì›** | 1536 (í¼) | ë©”ëª¨ë¦¬/ì†ë„ ë¹„íš¨ìœ¨ |

### 1.3 í•´ê²°ì±…: E5 ëª¨ë¸

**`multilingual-e5-small-ko-v2`**
```
- í¬ê¸°: 33.4M íŒŒë¼ë¯¸í„° (ê°€ë³ê³  ë¹ ë¦„)
- ì°¨ì›: 384 (í˜„ì¬ 1536 â†’ 75% ê°ì†Œ)
- í•œêµ­ì–´: âœ… ì™„ë²½ ì§€ì›
- ë©€í‹°ë§ê¸€: âœ… í•œì˜ì¼ í˜¼ìš© ì§€ì›
- ì˜ë¯¸ ì„ë² ë”©: âœ… ë³€ì••ê¸° ê¸°ë°˜ (Transformer)
- ë¼ì´ì„ ìŠ¤: Open-source (MIT)
```

### 1.4 ë³€ê²½ ë²”ìœ„

| êµ¬ë¶„ | íŒŒì¼/ëª¨ë“ˆ | ë³€ê²½ ìœ í˜• | ì„¤ëª… |
|------|----------|----------|------|
| **ì˜ì¡´ì„±** | `pyproject.toml` | ì¶”ê°€ | `sentence-transformers>=2.2.0` |
| **ì„¤ì •** | `app/core/config.py` | ìˆ˜ì • | `vectorstore_dimension=384`, `embedding_model="e5"` |
| **LLM ëª¨ë“ˆ** | `app/llm/embedder.py` | ì‹ ê·œ ìƒì„± | E5Embedder í´ë˜ìŠ¤ (ë¡œì»¬ ì„ë² ë”©) |
| **VectorStore** | `app/vectorstore/pgvector.py` | ìˆ˜ì • | `_embed_text()` â†’ E5 í˜¸ì¶œë¡œ ë³€ê²½ |
| **VectorStore Mock** | `app/vectorstore/mock.py` | ìˆ˜ì • | Mock ì„ë² ë”©ë„ E5 ë°©ì‹ìœ¼ë¡œ ë³€ê²½ |
| **DB ë§ˆì´ê·¸ë ˆì´ì…˜** | `alembic/versions/` | ì‹ ê·œ ìƒì„± | ë²¡í„° ì°¨ì› ë³€ê²½ (1536 â†’ 384) |
| **í…ŒìŠ¤íŠ¸** | `tests/unit/test_embeddings.py` | ì‹ ê·œ ìƒì„± | ì„ë² ë”© ì •í™•ë„ ê²€ì¦ |

### 1.5 ì„¤ê³„ ì›ì¹™

**1. ì¶”ìƒí™” ìœ ì§€**
- `VectorStoreProtocol` ë³€ê²½ ì—†ìŒ
- `_embed_text()` ë©”ì„œë“œë§Œ êµì²´

**2. LLM í´ë¼ì´ì–¸íŠ¸ì™€ ë…ë¦½**
- EmbedderëŠ” ë³„ë„ ëª¨ë“ˆ (`app/llm/embedder.py`)
- LLMClientProtocol (text generation) â‰  Embedder (embedding)

**3. ë¡œì»¬ ìš°ì„ **
- ëª¨ë“  ì„ë² ë”©ì„ ë¡œì»¬ì—ì„œ ì²˜ë¦¬
- í–¥í›„ OpenAI ì„ë² ë”©ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œ ê°€ëŠ¥ (ì„ íƒì‚¬í•­)

**4. ì„±ëŠ¥ ìµœì í™”**
- ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì†ë„ í–¥ìƒ
- ëª¨ë¸ ì‹±ê¸€í†¤ìœ¼ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨í™”

---

## 2. ìƒì„¸ ì„¤ê³„

### 2.1 E5Embedder í´ë˜ìŠ¤ (ì‹ ê·œ)

```python
# app/llm/embedder.py

from typing import Optional
from sentence_transformers import SentenceTransformer
import numpy as np
from app.core.config import settings
from app.core.logging import get_logger

logger = get_logger(__name__)


class E5Embedder:
    """ë¡œì»¬ E5 ëª¨ë¸ ê¸°ë°˜ ì„ë² ë”© ìƒì„±ê¸°"""

    _instance: Optional["E5Embedder"] = None  # ì‹±ê¸€í†¤

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._initialized = False
        return cls._instance

    def __init__(self):
        if self._initialized:
            return

        logger.info("e5_embedder_loading", model="multilingual-e5-small-ko-v2")
        self.model = SentenceTransformer(
            'dragonkue/multilingual-e5-small-ko-v2',
            device=settings.embedding_device  # 'cpu' ë˜ëŠ” 'cuda'
        )
        self.dimension = 384
        self._initialized = True
        logger.info("e5_embedder_loaded", dimension=self.dimension)

    async def embed(self, text: str) -> list[float]:
        """ë‹¨ì¼ í…ìŠ¤íŠ¸ ì„ë² ë”©"""
        embedding = self.model.encode(text, convert_to_numpy=True)
        # L2 ì •ê·œí™” (ê¸°ì¡´ bag-of-wordsì™€ í˜¸í™˜ì„±)
        norm = np.linalg.norm(embedding)
        normalized = embedding / (norm + 1e-8)
        return normalized.tolist()

    async def embed_batch(self, texts: list[str]) -> list[list[float]]:
        """ë°°ì¹˜ ì²˜ë¦¬ (ì†ë„ ìµœì í™”)"""
        embeddings = self.model.encode(texts, convert_to_numpy=True)
        # L2 ì •ê·œí™”
        norms = np.linalg.norm(embeddings, axis=1, keepdims=True)
        normalized = embeddings / (norms + 1e-8)
        return normalized.tolist()

    async def similarity(self, text1: str, text2: str) -> float:
        """ë‘ í…ìŠ¤íŠ¸ ê°„ ìœ ì‚¬ë„ ê³„ì‚° (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)"""
        embeddings = await self.embed_batch([text1, text2])
        vec1, vec2 = np.array(embeddings[0]), np.array(embeddings[1])
        # ì •ê·œí™”ëœ ë²¡í„°ì´ë¯€ë¡œ ë‚´ì  = ì½”ì‚¬ì¸ ìœ ì‚¬ë„
        similarity = float(np.dot(vec1, vec2))
        return max(0.0, min(1.0, similarity))  # [0, 1] ë²”ìœ„ í´ë¦½


def get_e5_embedder() -> E5Embedder:
    """E5Embedder ì‹±ê¸€í†¤ íšë“"""
    return E5Embedder()
```

### 2.2 ì„¤ì • í™•ì¥ (app/core/config.py)

```python
from typing import Literal

class Settings(BaseSettings):
    # ... ê¸°ì¡´ ì„¤ì • ...

    # Embedding Configuration (NEW)
    embedding_model: Literal["e5", "openai", "mock"] = "e5"
    embedding_device: Literal["cpu", "cuda"] = "cpu"  # GPU ì§€ì›

    # VectorStore (ìˆ˜ì •)
    vectorstore_dimension: int = 384  # 1536 â†’ 384 (E5 ì°¨ì›)

    # ê¸°ì¡´ ì„¤ì • ìœ ì§€
    pgvector_table_consultation: str = "consultation_vectors"
    pgvector_table_manual: str = "manual_vectors"
```

### 2.3 VectorStore ìˆ˜ì • (app/vectorstore/pgvector.py)

```python
# app/vectorstore/pgvector.py

from app.llm.embedder import get_e5_embedder
from app.core.config import settings

class PGVectorStore(VectorStoreProtocol):
    """pgvector ê¸°ë°˜ VectorStore (E5 ì„ë² ë”©)"""

    def __init__(self, index_name: str, engine: AsyncEngine | None = None) -> None:
        self.index_name = index_name
        self.engine = engine or get_async_engine()
        self.dimension = settings.vectorstore_dimension  # 384
        self.table_name = self._resolve_table_name(index_name)
        self._init_lock = asyncio.Lock()
        self._initialized = False

        # E5 ì„ë² ë” íšë“
        if settings.embedding_model == "e5":
            self.embedder = get_e5_embedder()
        else:
            # í–¥í›„ OpenAI ë“± ë‹¤ë¥¸ ì„ë² ë” ì§€ì› ê°€ëŠ¥
            self.embedder = None

    async def index_document(
        self,
        id: UUID,
        text: str,
        metadata: dict | None = None,
    ) -> None:
        """ë¬¸ì„œ ì¸ë±ì‹±"""
        await self._ensure_initialized()

        # E5 ëª¨ë¸ë¡œ ì„ë² ë”© ìƒì„±
        embedding = await self.embedder.embed(text)
        metadata = metadata or {}
        metadata_json = self._normalize_metadata(metadata)

        # ... ê¸°ì¡´ UPSERT ë¡œì§ (ë³€ê²½ ì—†ìŒ)

    async def search(
        self,
        query: str,
        top_k: int = 10,
        metadata_filter: dict | None = None,
    ) -> list[VectorSearchResult]:
        """ì˜ë¯¸ë¡ ì  ê²€ìƒ‰"""
        await self._ensure_initialized()

        # E5 ëª¨ë¸ë¡œ ì¿¼ë¦¬ ì„ë² ë”©
        query_embedding = await self.embedder.embed(query)

        # ... ê¸°ì¡´ SQL ë¡œì§ (ë³€ê²½ ì—†ìŒ)

    async def similarity(self, text1: str, text2: str) -> float:
        """ìœ ì‚¬ë„ ê³„ì‚° (ComparisonServiceì—ì„œ ì‚¬ìš©)"""
        return await self.embedder.similarity(text1, text2)

    def _embed_text(self, text: str) -> list[float]:
        """
        íê¸° ì˜ˆì • (ë¹„ë™ê¸° ë²„ì „ì¸ embed() ì‚¬ìš©)

        í˜¸í™˜ì„±ì„ ìœ„í•´ ë™ê¸° ë²„ì „ë„ ìœ ì§€
        ì£¼ì˜: ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ì—ì„œëŠ” ì‚¬ìš© ë¶ˆê°€
        """
        raise NotImplementedError(
            "Use embedder.embed() (async) instead of _embed_text()"
        )
```

### 2.4 Mock VectorStore ìˆ˜ì • (app/vectorstore/mock.py)

```python
# app/vectorstore/mock.py

from app.llm.embedder import get_e5_embedder

class MockVectorStore(VectorStoreProtocol):
    """ë©”ëª¨ë¦¬ ê¸°ë°˜ Mock VectorStore (E5 ì„ë² ë”©)"""

    def __init__(self, index_name: str = "mock"):
        self.index_name = index_name
        self.documents: dict[UUID, dict] = {}  # id â†’ {embedding, metadata}
        self.dimension = 384  # E5 ì°¨ì›
        self.embedder = get_e5_embedder()

    async def index_document(
        self,
        id: UUID,
        text: str,
        metadata: dict | None = None,
    ) -> None:
        """ë©”ëª¨ë¦¬ì— ë¬¸ì„œ ì €ì¥"""
        embedding = await self.embedder.embed(text)
        self.documents[id] = {
            "embedding": embedding,
            "metadata": metadata or {},
            "text": text,
        }

    async def search(
        self,
        query: str,
        top_k: int = 10,
        metadata_filter: dict | None = None,
    ) -> list[VectorSearchResult]:
        """ë©”ëª¨ë¦¬ì—ì„œ ê²€ìƒ‰"""
        query_embedding = await self.embedder.embed(query)

        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        results = []
        for doc_id, doc in self.documents.items():
            # ë©”íƒ€ë°ì´í„° í•„í„° í™•ì¸
            metadata = doc["metadata"]
            if metadata_filter:
                if not all(
                    metadata.get(k) == v
                    for k, v in metadata_filter.items()
                ):
                    continue

            # ìœ ì‚¬ë„ ê³„ì‚°
            similarity = self._cosine_similarity(
                query_embedding, doc["embedding"]
            )
            results.append(
                VectorSearchResult(
                    id=doc_id,
                    score=similarity,
                    metadata=metadata,
                )
            )

        # ìƒìœ„ kê°œ ë°˜í™˜
        return sorted(results, key=lambda x: x.score, reverse=True)[:top_k]

    async def similarity(self, text1: str, text2: str) -> float:
        """ìœ ì‚¬ë„ ê³„ì‚°"""
        return await self.embedder.similarity(text1, text2)

    @staticmethod
    def _cosine_similarity(vec1: list[float], vec2: list[float]) -> float:
        """ì½”ì‚¬ì¸ ìœ ì‚¬ë„"""
        import numpy as np
        v1, v2 = np.array(vec1), np.array(vec2)
        return float(np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2) + 1e-8))
```

### 2.5 DB ë§ˆì´ê·¸ë ˆì´ì…˜

```python
# alembic/versions/20251218_0001_e5_embeddings_dimension_384.py

"""ì—…ë°ì´íŠ¸ ë²¡í„° ì°¨ì› to 384 (E5 ëª¨ë¸)

Revision ID: 20251218_0001
Revises: 20251216_0004
Create Date: 2025-12-18 14:00:00.000000

"""

from alembic import op
import sqlalchemy as sa
from pgvector.sqlalchemy import Vector

def upgrade():
    """ë²¡í„° ì°¨ì› 1536 â†’ 384ë¡œ ë³€ê²½"""

    # 1. ê¸°ì¡´ í…Œì´ë¸” ë°±ì—… (ë°ì´í„° ë³´ì¡´)
    op.execute("""
        CREATE TABLE consultation_vectors_old AS
        SELECT * FROM consultation_vectors;
    """)
    op.execute("""
        CREATE TABLE manual_vectors_old AS
        SELECT * FROM manual_vectors;
    """)

    # 2. ê¸°ì¡´ í…Œì´ë¸” ì‚­ì œ
    op.drop_table('consultation_vectors')
    op.drop_table('manual_vectors')

    # 3. ìƒˆë¡œìš´ í…Œì´ë¸” ìƒì„± (ì°¨ì› 384)
    op.create_table(
        'consultation_vectors',
        sa.Column('id', sa.UUID(), nullable=False),
        sa.Column('embedding', Vector(384), nullable=False),
        sa.Column('metadata', sa.JSON(), nullable=False),
        sa.Column('branch_code', sa.String(50), nullable=True),
        sa.Column('business_type', sa.String(50), nullable=True),
        sa.Column('error_code', sa.String(50), nullable=True),
        sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.func.now()),
        sa.PrimaryKeyConstraint('id'),
    )

    op.create_table(
        'manual_vectors',
        sa.Column('id', sa.UUID(), nullable=False),
        sa.Column('embedding', Vector(384), nullable=False),
        sa.Column('metadata', sa.JSON(), nullable=False),
        sa.Column('business_type', sa.String(50), nullable=True),
        sa.Column('error_code', sa.String(50), nullable=True),
        sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.func.now()),
        sa.PrimaryKeyConstraint('id'),
    )

    # 4. ì¸ë±ìŠ¤ ìƒì„±
    op.create_index('idx_consultation_vectors_branch', 'consultation_vectors', ['branch_code'])
    op.create_index('idx_consultation_vectors_business', 'consultation_vectors', ['business_type'])
    op.create_index('idx_consultation_vectors_error', 'consultation_vectors', ['error_code'])
    op.create_index('idx_manual_vectors_business', 'manual_vectors', ['business_type'])
    op.create_index('idx_manual_vectors_error', 'manual_vectors', ['error_code'])

def downgrade():
    """ë¡¤ë°±: ë²¡í„° ì°¨ì› 384 â†’ 1536"""

    op.drop_table('consultation_vectors')
    op.drop_table('manual_vectors')

    # ë°±ì—…ì—ì„œ ë³µêµ¬
    op.execute("""
        CREATE TABLE consultation_vectors AS
        SELECT * FROM consultation_vectors_old;
    """)
    op.execute("""
        CREATE TABLE manual_vectors AS
        SELECT * FROM manual_vectors_old;
    """)

    op.drop_table('consultation_vectors_old')
    op.drop_table('manual_vectors_old')
```

---

## 3. êµ¬í˜„ ë‹¨ê³„ (Timeline)

### Phase 1: ì˜ì¡´ì„± + ì„¤ì • (1ì‹œê°„)

**íŒŒì¼:**
- `pyproject.toml`: `sentence-transformers>=2.2.0` ì¶”ê°€
- `app/core/config.py`: ìƒˆ ì„¤ì • í•„ë“œ ì¶”ê°€
- `.env.example`: ìƒˆ í™˜ê²½ë³€ìˆ˜ ì¶”ê°€

```bash
# .env
EMBEDDING_MODEL=e5
EMBEDDING_DEVICE=cpu  # ë˜ëŠ” cuda
VECTORSTORE_DIMENSION=384
```

### Phase 2: Embedder êµ¬í˜„ (2ì‹œê°„)

**íŒŒì¼:**
- `app/llm/embedder.py` (ì‹ ê·œ): E5Embedder í´ë˜ìŠ¤

**ì²´í¬í¬ì¸íŠ¸:**
```python
# í…ŒìŠ¤íŠ¸
embedder = get_e5_embedder()
embedding = await embedder.embed("ì‹ ìš©ì¹´ë“œ ê²°ì œ ì˜¤ë¥˜")
assert len(embedding) == 384
```

### Phase 3: VectorStore ìˆ˜ì • (1.5ì‹œê°„)

**íŒŒì¼:**
- `app/vectorstore/pgvector.py`: `_embed_text()` â†’ `embedder.embed()`
- `app/vectorstore/mock.py`: Mockë„ E5 ì ìš©

**ì²´í¬í¬ì¸íŠ¸:**
```python
# í…ŒìŠ¤íŠ¸
vectorstore = PGVectorStore("consultations")
await vectorstore.index_document(
    id=uuid.uuid4(),
    text="ì‹ ìš©ì¹´ë“œ ê²°ì œ ì˜¤ë¥˜",
    metadata={"branch_code": "001"}
)

results = await vectorstore.search(
    query="ì¹´ë“œ ê²°ì œ ì‹¤íŒ¨",
    top_k=5
)
assert len(results) > 0
assert results[0].score > 0.8  # E5 ëª¨ë¸ì´ë¼ ë†’ì€ ìœ ì‚¬ë„
```

### Phase 4: DB ë§ˆì´ê·¸ë ˆì´ì…˜ (0.5ì‹œê°„)

**íŒŒì¼:**
- `alembic/versions/20251218_0001_*.py` (ì‹ ê·œ)

```bash
# ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
uv run alembic upgrade head
```

### Phase 5: í…ŒìŠ¤íŠ¸ ì‘ì„± (2ì‹œê°„)

**íŒŒì¼:**
- `tests/unit/test_e5_embedder.py` (ì‹ ê·œ)
- `tests/unit/test_vectorstore_e5.py` (ì‹ ê·œ)

**í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤:**

```python
# tests/unit/test_e5_embedder.py

@pytest.mark.asyncio
async def test_e5_embed_korean_text():
    """í•œêµ­ì–´ ì„ë² ë”©"""
    embedder = get_e5_embedder()
    embedding = await embedder.embed("ì‹ ìš©ì¹´ë“œ ê²°ì œ ì˜¤ë¥˜")
    assert len(embedding) == 384
    assert all(-1 <= x <= 1 for x in embedding)


@pytest.mark.asyncio
async def test_e5_similarity_korean():
    """í•œêµ­ì–´ ìœ ì‚¬ë„ (ë™ì˜ì–´ ì¸ì‹)"""
    embedder = get_e5_embedder()

    # ë™ì˜ì–´
    sim1 = await embedder.similarity(
        "ì‹ ìš©ì¹´ë“œ ê²°ì œ ì˜¤ë¥˜",
        "ì¹´ë“œ ê²°ì œ ì‹¤íŒ¨"
    )
    assert sim1 > 0.8  # ë†’ì€ ìœ ì‚¬ë„

    # ë¹„ê´€ë ¨
    sim2 = await embedder.similarity(
        "ì‹ ìš©ì¹´ë“œ ê²°ì œ ì˜¤ë¥˜",
        "ë‚ ì”¨ê°€ ë§‘ìŠµë‹ˆë‹¤"
    )
    assert sim2 < 0.3  # ë‚®ì€ ìœ ì‚¬ë„


@pytest.mark.asyncio
async def test_vectorstore_search_with_e5():
    """VectorStore ê²€ìƒ‰ (ì˜ë¯¸ë¡ ì )"""
    vectorstore = MockVectorStore("test")

    # ë¬¸ì„œ ì¸ë±ì‹±
    await vectorstore.index_document(
        id=uuid.uuid4(),
        text="ì‹ ìš©ì¹´ë“œë¡œ ê²°ì œí•  ë•Œ CVV ì¸ì¦ ì‹¤íŒ¨",
        metadata={"business_type": "ì¹´ë“œê²°ì œ"}
    )

    # ê²€ìƒ‰ (ë‹¤ë¥¸ í‘œí˜„)
    results = await vectorstore.search(
        query="ì¹´ë“œ ê²°ì œ ì˜¤ë¥˜",
        metadata_filter={"business_type": "ì¹´ë“œê²°ì œ"}
    )

    assert len(results) == 1
    assert results[0].score > 0.7  # E5 ëª¨ë¸ ë•ë¶„ì— ë†’ì€ ìœ ì‚¬ë„
```

### Phase 6: í†µí•© í…ŒìŠ¤íŠ¸ (1ì‹œê°„)

```bash
# ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
uv run pytest tests/ -v

# E5 íŠ¹í™” í…ŒìŠ¤íŠ¸
uv run pytest tests/unit/test_e5_embedder.py -v
uv run pytest tests/unit/test_vectorstore_e5.py -v
```

---

## 4. ì„±ëŠ¥ ë¹„êµ

### ì„ë² ë”© ìƒì„± ì‹œê°„ (ë¡œì»¬ CPU)

| ëª¨ë¸ | ë‹¨ì¼ í…ìŠ¤íŠ¸ | ë°°ì¹˜ (100ê°œ) |
|------|-----------|------------|
| Bag-of-words | 1ms | 50ms |
| **E5 (ì²« ì‹¤í–‰)** | 500ms | 1s |
| **E5 (ë¡œë“œë¨)** | 50-100ms | 500ms |

**ê²°ë¡ :** ì´ˆê¸° ë¡œë”© í›„ì—ëŠ” ê´œì°®ì€ ì„±ëŠ¥

### ì˜ë¯¸ ì •í™•ë„

| í…ŒìŠ¤íŠ¸ | Bag-of-words | E5 ëª¨ë¸ |
|------|-------------|--------|
| "ì‹ ìš©ì¹´ë“œ ê²°ì œ ì˜¤ë¥˜" ê²€ìƒ‰<br/>"ì¹´ë“œ ê²°ì œ ì‹¤íŒ¨" | âŒ 0.4 ìœ ì‚¬ë„ | âœ… 0.92 ìœ ì‚¬ë„ |
| "ì—ëŸ¬" vs "ì—ëŸ¬" | âœ… ì •í™• ì¼ì¹˜ | âœ… 1.0 ìœ ì‚¬ë„ |
| "ê²°ì œ" vs "ê²°ì œ" | âœ… ì •í™• ì¼ì¹˜ | âœ… 1.0 ìœ ì‚¬ë„ |
| "ì˜¤ë¥˜" vs "ì—ëŸ¬" | âŒ 0.0 (ë‹¤ë¥¸ ë‹¨ì–´) | âœ… 0.85 ìœ ì‚¬ë„ |

---

## 5. ì£¼ì˜ì‚¬í•­ ë° íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 5.1 ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰

**E5 ëª¨ë¸ ë¡œë“œ:**
- ë©”ëª¨ë¦¬: ~500MB (ëª¨ë¸ ê°€ì¤‘ì¹˜ + ì„ë² ë”© ìºì‹œ)
- GPU: ìµœëŒ€ 2GB (cuda ì‚¬ìš© ì‹œ)

**í•´ê²°ì±…:**
```python
# CPU ì‚¬ìš© (ê¸°ë³¸)
EMBEDDING_DEVICE=cpu

# GPU ì‚¬ìš© (ê¶Œì¥, í”„ë¡œë•ì…˜)
EMBEDDING_DEVICE=cuda
```

### 5.2 ì²« ì„ë² ë”©ì´ ëŠë¦¼

**ì›ì¸:** ëª¨ë¸ ë¡œë“œ ì‹œê°„ (~2-3ì´ˆ)

**í•´ê²°ì±…:**
```python
# ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ ì‚¬ì „ ë¡œë“œ
async def app_startup():
    embedder = get_e5_embedder()
    await embedder.embed("ì›Œë°ì—…")  # ëª¨ë¸ ë¡œë“œ
    logger.info("E5 embedder warmed up")
```

### 5.3 ë²¡í„° ì°¨ì› ë³€ê²½ í›„ ê²€ìƒ‰ ë¶ˆê°€

**ì›ì¸:** ê¸°ì¡´ ë²¡í„° (1536ì°¨ì›) vs ìƒˆ ì¿¼ë¦¬ (384ì°¨ì›)

**í•´ê²°ì±…:** ë§ˆì´ê·¸ë ˆì´ì…˜ìœ¼ë¡œ ì „ì²´ ë²¡í„° ì¬ìƒì„± í•„ìˆ˜

```bash
# ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
uv run alembic upgrade head

# ê¸°ì¡´ ë°ì´í„° ì¬ì¸ë±ì‹± (ìŠ¤í¬ë¦½íŠ¸)
uv run python scripts/reindex_vectors.py
```

### 5.4 ì°¨ì› ë¶ˆì¼ì¹˜ ì—ëŸ¬

```
pgvector.errors.DimensionMismatch: vector size must be 384, not 1536
```

**í•´ê²°ì±…:**
```bash
# ë²¡í„° í…Œì´ë¸” í™•ì¸
psql khw -c "SELECT dimension FROM vector_index_dimensions WHERE table_name='consultation_vectors';"
# ê²°ê³¼: 384 âœ…
```

---

## 6. ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ëµ

### 6.1 ê¸°ì¡´ ë°ì´í„° ë³´ì¡´ (ê¶Œì¥)

```bash
# Step 1: ë°±ì—…
pg_dump -U postgres khw > backup_before_e5.sql

# Step 2: ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
uv run alembic upgrade head

# Step 3: ë°ì´í„° ì¬ì¸ë±ì‹±
uv run python scripts/reindex_vectors.py

# Step 4: ê²€ì¦
uv run pytest tests/unit/test_vectorstore_e5.py -v
```

### 6.2 ë°ì´í„° ì¬ì¸ë±ì‹± ìŠ¤í¬ë¦½íŠ¸

```python
# scripts/reindex_vectors.py

import asyncio
from app.core.db import get_async_session
from app.repositories.consultation_rdb import ConsultationRDBRepository
from app.repositories.manual_rdb import ManualRDBRepository
from app.vectorstore.pgvector import PGVectorStore

async def reindex_all():
    """ëª¨ë“  ìƒë‹´/ë©”ë‰´ì–¼ ë²¡í„° ì¬ìƒì„±"""

    # VectorStore ì¤€ë¹„
    consultation_vs = PGVectorStore("consultations")
    manual_vs = PGVectorStore("manuals")

    async with get_async_session() as session:
        # ìƒë‹´ ì¬ì¸ë±ì‹±
        consultation_repo = ConsultationRDBRepository(session)
        consultations = await consultation_repo.list_all()

        for consultation in consultations:
            text = f"[ìš”ì•½]{consultation.summary}\n[ë¬¸ì˜]{consultation.inquiry_text}\n[ì¡°ì¹˜]{consultation.action_taken}"
            await consultation_vs.index_document(
                id=consultation.id,
                text=text,
                metadata={
                    "branch_code": consultation.branch_code,
                    "business_type": consultation.business_type,
                    "error_code": consultation.error_code,
                    "created_at": consultation.created_at,
                }
            )
            print(f"âœ… Reindexed consultation: {consultation.id}")

        # ë§¤ë‰´ì–¼ ì¬ì¸ë±ì‹± (APPROVEDë§Œ)
        manual_repo = ManualRDBRepository(session)
        manuals = await manual_repo.find_by_status("APPROVED")

        for manual in manuals:
            text = f"[í‚¤ì›Œë“œ]{','.join(manual.keywords)}\n[ì£¼ì œ]{manual.topic}\n[ë°°ê²½]{manual.background}\n[ê°€ì´ë“œë¼ì¸]{manual.guideline}"
            await manual_vs.index_document(
                id=manual.id,
                text=text,
                metadata={
                    "business_type": manual.business_type,
                    "error_code": manual.error_code,
                    "created_at": manual.created_at,
                }
            )
            print(f"âœ… Reindexed manual: {manual.id}")

if __name__ == "__main__":
    asyncio.run(reindex_all())
```

---

## 7. ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸

### êµ¬í˜„ ì™„ë£Œ í™•ì¸

- [ ] `pyproject.toml`ì— `sentence-transformers` ì¶”ê°€
- [ ] `app/llm/embedder.py` (E5Embedder) êµ¬í˜„ ì™„ë£Œ
- [ ] `app/core/config.py` ì„¤ì • í•„ë“œ ì¶”ê°€
- [ ] `app/vectorstore/pgvector.py` E5 ì ìš©
- [ ] `app/vectorstore/mock.py` E5 ì ìš©
- [ ] `alembic/versions/` ë§ˆì´ê·¸ë ˆì´ì…˜ ì‘ì„±
- [ ] `tests/unit/test_e5_embedder.py` ì‘ì„±
- [ ] `tests/unit/test_vectorstore_e5.py` ì‘ì„±
- [ ] `scripts/reindex_vectors.py` ì‘ì„±

### í…ŒìŠ¤íŠ¸ ì™„ë£Œ í™•ì¸

```bash
# ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
uv run pytest tests/unit/test_e5_embedder.py -v
uv run pytest tests/unit/test_vectorstore_e5.py -v

# í†µí•© í…ŒìŠ¤íŠ¸
uv run pytest tests/ -v

# ì½”ë“œ í’ˆì§ˆ
uv run black app/ tests/
uv run ruff check app/ tests/ --fix
uv run mypy app/
```

### ì„±ëŠ¥ ê²€ì¦

```python
# ì„ë² ë”© ì†ë„ í…ŒìŠ¤íŠ¸
import time
from app.llm.embedder import get_e5_embedder

async def test_speed():
    embedder = get_e5_embedder()

    texts = ["ì‹ ìš©ì¹´ë“œ ê²°ì œ ì˜¤ë¥˜"] * 100

    start = time.time()
    embeddings = await embedder.embed_batch(texts)
    elapsed = time.time() - start

    print(f"100ê°œ ë°°ì¹˜ ì„ë² ë”©: {elapsed:.2f}ì´ˆ")
    print(f"í‰ê· : {elapsed/100*1000:.2f}ms/ê°œ")
```

---

## 8. í–¥í›„ í™•ì¥ ê³„íš

### 8.1 ë©€í‹° ëª¨ë¸ ì§€ì›

```python
# í–¥í›„: ì—¬ëŸ¬ ì„ë² ë”© ëª¨ë¸ ì„ íƒ ê°€ëŠ¥
EMBEDDING_MODEL=e5          # í˜„ì¬ (ë¡œì»¬)
EMBEDDING_MODEL=openai      # í–¥í›„ (ë¹„ìš©)
EMBEDDING_MODEL=cohere      # í–¥í›„ (ê³ ì„±ëŠ¥)
```

### 8.2 GPU ìµœì í™”

```python
# CUDA ì§€ì›ìœ¼ë¡œ ì†ë„ í–¥ìƒ (50-100ms â†’ 20-30ms)
EMBEDDING_DEVICE=cuda
```

### 8.3 ë²¡í„° ìºì‹±

```python
# ìì£¼ ì‚¬ìš©í•˜ëŠ” í…ìŠ¤íŠ¸ ì„ë² ë”© ìºì‹±
from functools import lru_cache

@lru_cache(maxsize=1000)
async def cached_embed(text: str) -> list[float]:
    ...
```

---

## 9. ì°¸ê³ ìë£Œ

- **E5 ëª¨ë¸**: https://huggingface.co/dragonkue/multilingual-e5-small-ko-v2
- **Sentence Transformers**: https://www.sbert.net/
- **ê¸°ì¡´ ê°€ì´ë“œ**: [onboarding.md - ë²¡í„° DB ì„ë² ë”©](onboarding.md#-ë²¡í„°-db-ì„ë² ë”©-ìƒì„¸-ë¶„ì„)

---

## 10. ë³€ê²½ ì´ë ¥

| ë‚ ì§œ | ë²„ì „ | ë³€ê²½ì‚¬í•­ |
|------|------|---------|
| 2025-12-18 | 1.0 | ì´ˆì•ˆ ì‘ì„± |
